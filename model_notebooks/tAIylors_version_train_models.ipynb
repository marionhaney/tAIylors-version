{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "95bca6dc4a6942bfa7c19697ed3749f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9adeb88f57241d3a11ccaaa4102854c",
              "IPY_MODEL_b6c39ecb01804e27ba7ff19fd9eb44fc",
              "IPY_MODEL_4d9c4631d2704987ae0ab80c523d4304"
            ],
            "layout": "IPY_MODEL_2f631308ad2244c18c91431e47bde2bd"
          }
        },
        "f9adeb88f57241d3a11ccaaa4102854c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b988f85601a413a86625cc83e3d31dc",
            "placeholder": "​",
            "style": "IPY_MODEL_d612d409973b45e8b5a455a804ad1a5b",
            "value": "Map: 100%"
          }
        },
        "b6c39ecb01804e27ba7ff19fd9eb44fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b292af27089a43a19ab01b174b744a70",
            "max": 1719,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e396d5dbf3aa45abadf85a2bdaeb9e97",
            "value": 1719
          }
        },
        "4d9c4631d2704987ae0ab80c523d4304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_633c8c6b997846c3a274e8412690e99b",
            "placeholder": "​",
            "style": "IPY_MODEL_ea36d20871d249e0bbfa091d26c6ccf2",
            "value": " 1719/1719 [00:00&lt;00:00, 2287.99 examples/s]"
          }
        },
        "2f631308ad2244c18c91431e47bde2bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b988f85601a413a86625cc83e3d31dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d612d409973b45e8b5a455a804ad1a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b292af27089a43a19ab01b174b744a70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e396d5dbf3aa45abadf85a2bdaeb9e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "633c8c6b997846c3a274e8412690e99b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea36d20871d249e0bbfa091d26c6ccf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3182d7c42cb5499aa8259bf1e4729c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a1572b8a22b48868c5dee40e993ef33",
              "IPY_MODEL_c93366dcb0ca4387a4f6248ccd1c0c39",
              "IPY_MODEL_7b43152bd73d40c6a75212c64297b5ef"
            ],
            "layout": "IPY_MODEL_9713796a421a4640a145019840c94068"
          }
        },
        "9a1572b8a22b48868c5dee40e993ef33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_444b9020d45c49fc9a9826a0ebb38000",
            "placeholder": "​",
            "style": "IPY_MODEL_35e6f0fa8ef748f39b9e54234b625ac0",
            "value": "Map: 100%"
          }
        },
        "c93366dcb0ca4387a4f6248ccd1c0c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52e121f3468445639795d33dffe32331",
            "max": 430,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de0b3e6d0fd64c84b8920c8c7773f365",
            "value": 430
          }
        },
        "7b43152bd73d40c6a75212c64297b5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_450c6b10d8374e7c992f7658d9d0e87e",
            "placeholder": "​",
            "style": "IPY_MODEL_d33c288ee112470ebd3b77c790e23b11",
            "value": " 430/430 [00:00&lt;00:00, 1483.15 examples/s]"
          }
        },
        "9713796a421a4640a145019840c94068": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "444b9020d45c49fc9a9826a0ebb38000": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35e6f0fa8ef748f39b9e54234b625ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52e121f3468445639795d33dffe32331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de0b3e6d0fd64c84b8920c8c7773f365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "450c6b10d8374e7c992f7658d9d0e87e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d33c288ee112470ebd3b77c790e23b11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training tAIylor's version models\n",
        "\n",
        "We will fine tune two HuggingFace models with Taylor Swift lyrics. One BERT model will be used to classify which era (or album/album group) lyrics are from and the GPT 2 model will generate lyrics.\n",
        "\n",
        "### Data:\n",
        "\n",
        "The data has two fields: label and text\n",
        "\n",
        "**label:** the integer of the album or album group from which the lyrics come from. The eras are taylor_swift, speak_now, reputation, nineteen89, red, lover, folklore, evermore\n",
        "Some versions have this grouped together: all eras version, Biber version, genre version\n",
        "\n",
        "**text:** 4 lines of lyrics from a song on the album or 8 lines of lyrics from a song on the album"
      ],
      "metadata": {
        "id": "UwPCYCd8NSU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pandas\n",
        "!pip install sklearn.model_selection\n",
        "!pip install google.colab\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "Y120EHsnXwAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Load in the data\n",
        "data = pd.read_csv(\"/content/drive/My Drive/Grad/Text Analysis/fine_tune_data_genre_l4.csv\")\n",
        "\n",
        "# Split data into test and training\n",
        "# Split the data into features (X) and labels (y)\n",
        "X = data[\"text\"]\n",
        "y = data[\"label\"]\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
        "\n",
        "# Create pandas DataFrames for train and test\n",
        "train_data = pd.DataFrame({\"text\": X_train, \"label\": y_train})\n",
        "test_data = pd.DataFrame({\"text\": X_test, \"label\": y_test})\n",
        "\n",
        "# Display the shapes of the training and testing sets\n",
        "print(\"Training set shape: \", train_data.shape)\n",
        "print(\"Testing set shape: \", test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y78g7t9SEJz",
        "outputId": "57ae3dca-db76-4478-e341-e3c7a1275de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Training set shape:  (1719, 2)\n",
            "Testing set shape:  (430, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT training for classification\n",
        "\n",
        "Model used: bert-base-cased\n",
        "\n",
        "https://huggingface.co/bert-base-cased"
      ],
      "metadata": {
        "id": "05lGJng8Rryt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-H2YJWlUc91"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install evaluate\n",
        "!pip install transformers[torch] -U\n",
        "!pip install accelerate -U\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from datasets import Dataset, DatasetDict, load_dataset\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use GPU instead of CPU\n",
        "\n",
        "# Check if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    # Get the name of the GPU\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    print(f\"GPU: {gpu_name}\")\n",
        "else:\n",
        "    print(\"GPU is not available. Switch to a GPU runtime.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux7CTnz2aHST",
        "outputId": "463c4bb6-fa07-4fc1-ece8-9249f3f01f38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "# Create a function to preprocess data\n",
        "def preprocess(data):\n",
        "    return tokenizer(data[\"text\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "dataset_dict = {\n",
        "    \"train\": Dataset.from_pandas(train_data[['label', 'text']]),\n",
        "    \"test\": Dataset.from_pandas(test_data[['label', 'text']])\n",
        "}\n",
        "\n",
        "# Apply the preprocess function to both train and test splits\n",
        "for split in dataset_dict.keys():\n",
        "    dataset_dict[split] = dataset_dict[split].map(preprocess, batched=True)\n",
        "\n",
        "# Dynamically pad lyrics text to the length of the longest element in its batch\n",
        "data_collator = DataCollatorWithPadding(\n",
        "    tokenizer,\n",
        "    padding=True\n",
        ")\n",
        "\n",
        "dataset = DatasetDict(dataset_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "95bca6dc4a6942bfa7c19697ed3749f4",
            "f9adeb88f57241d3a11ccaaa4102854c",
            "b6c39ecb01804e27ba7ff19fd9eb44fc",
            "4d9c4631d2704987ae0ab80c523d4304",
            "2f631308ad2244c18c91431e47bde2bd",
            "7b988f85601a413a86625cc83e3d31dc",
            "d612d409973b45e8b5a455a804ad1a5b",
            "b292af27089a43a19ab01b174b744a70",
            "e396d5dbf3aa45abadf85a2bdaeb9e97",
            "633c8c6b997846c3a274e8412690e99b",
            "ea36d20871d249e0bbfa091d26c6ccf2",
            "3182d7c42cb5499aa8259bf1e4729c7d",
            "9a1572b8a22b48868c5dee40e993ef33",
            "c93366dcb0ca4387a4f6248ccd1c0c39",
            "7b43152bd73d40c6a75212c64297b5ef",
            "9713796a421a4640a145019840c94068",
            "444b9020d45c49fc9a9826a0ebb38000",
            "35e6f0fa8ef748f39b9e54234b625ac0",
            "52e121f3468445639795d33dffe32331",
            "de0b3e6d0fd64c84b8920c8c7773f365",
            "450c6b10d8374e7c992f7658d9d0e87e",
            "d33c288ee112470ebd3b77c790e23b11"
          ]
        },
        "id": "PKG9b8TOR0Z-",
        "outputId": "86750bd6-d080-4a0d-d23e-949f8ebd7216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1719 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95bca6dc4a6942bfa7c19697ed3749f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/430 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3182d7c42cb5499aa8259bf1e4729c7d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the evaluation process\n",
        "metrics = {\n",
        "    \"accuracy\": accuracy_score,\n",
        "    \"precision\": precision_score,\n",
        "    \"recall\": recall_score,\n",
        "    \"f1\": f1_score\n",
        "}\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p.predictions, p.label_ids\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    metrics_dict = {}\n",
        "    for metric_name, metric_func in metrics.items():\n",
        "        if metric_name == \"accuracy\":\n",
        "            metrics_dict[metric_name] = metric_func(labels, predictions)\n",
        "        else:\n",
        "            metrics_dict[metric_name] = metric_func(labels, predictions, average='weighted')\n",
        "\n",
        "    return metrics_dict\n",
        "\n",
        "# Load the pretrained model\n",
        "# all_eras: 9 labels\n",
        "# genre: 3 labels\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=3)\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        outputs = self.model(input_ids, token_type_ids=token_type_ids,\n",
        "                             attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "        return loss, logits\n",
        "\n",
        "# Instantiate custom model\n",
        "custom_model = CustomModel(model)\n",
        "\n",
        "# Move the model to the GPU if available\n",
        "custom_model.to(\"cuda\")\n",
        "\n",
        "# Set training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=8,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=custom_model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "amEmHg38ThHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, call the trainer\n",
        "%time trainer.train()"
      ],
      "metadata": {
        "id": "pZMh2fBQTT7t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "7d53246c-6551-4ca9-d1bc-b1ef3ddd9553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3440' max='3440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3440/3440 11:46, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.885300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.449000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.119800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.029900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 10min 45s, sys: 10.5 s, total: 10min 56s\n",
            "Wall time: 11min 47s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3440, training_loss=0.21694329294354417, metrics={'train_runtime': 707.1566, 'train_samples_per_second': 19.447, 'train_steps_per_second': 4.865, 'total_flos': 0.0, 'train_loss': 0.21694329294354417, 'epoch': 8.0})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model\n",
        "drive_path = \"/content/drive/My Drive/Grad/Text Analysis/\"\n",
        "\n",
        "model.save_pretrained(drive_path + \"tAIylors-version-model-genre-v2\")\n",
        "tokenizer.save_pretrained(drive_path + \"tAIylors-version-tokenizer-genre-v2\")"
      ],
      "metadata": {
        "id": "ZrZBQc-jYcUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e89b269-670b-4c48-e9e0-e65f44b3c067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/Grad/Text Analysis/tAIylors-version-genre-v2/tokenizer_config.json',\n",
              " '/content/drive/My Drive/Grad/Text Analysis/tAIylors-version-genre-v2/special_tokens_map.json',\n",
              " '/content/drive/My Drive/Grad/Text Analysis/tAIylors-version-genre-v2/vocab.txt',\n",
              " '/content/drive/My Drive/Grad/Text Analysis/tAIylors-version-genre-v2/added_tokens.json',\n",
              " '/content/drive/My Drive/Grad/Text Analysis/tAIylors-version-genre-v2/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate performance on the test set"
      ],
      "metadata": {
        "id": "pGT2o4XDs_Iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test set\n",
        "results = trainer.evaluate(dataset[\"test\"])\n",
        "\n",
        "# Print the evaluation results\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "vBRImyMUs-SG",
        "outputId": "f56f6027-d0c5-4d4b-862a-94d333520deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [108/108 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 1.0532838106155396, 'eval_accuracy': 0.8558139534883721, 'eval_precision': 0.8543025313612191, 'eval_recall': 0.8558139534883721, 'eval_f1': 0.8529464130606982, 'eval_runtime': 5.7891, 'eval_samples_per_second': 74.277, 'eval_steps_per_second': 18.656, 'epoch': 8.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a test example\n",
        "# Lyrics from Fearless (Fearless)\n",
        "# all_eras: 1\n",
        "# genre: 0\n",
        "test_example = '''There's somethin' bout the way\n",
        "The street looks when it's just rained\n",
        "There's a glow off the pavement\n",
        "You walk me to the car'''\n",
        "\n",
        "# Tokenize the test example\n",
        "tokens = tokenizer(test_example, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "tokens = {key: value.to(model.device) for key, value in tokens.items()}\n",
        "\n",
        "# Make a forward pass with the model\n",
        "with torch.no_grad():\n",
        "    outputs = model(**tokens)\n",
        "\n",
        "# Get the predicted label\n",
        "predicted_label = torch.argmax(outputs.logits).item()\n",
        "\n",
        "# Print the result\n",
        "print(f\"Predicted Label: {predicted_label}\")\n",
        "print(outputs.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL40d3GltqbG",
        "outputId": "492ac11a-341c-4db6-b8a8-7c0bb1d9a5ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: 0\n",
            "tensor([[ 6.5254, -3.7612, -2.8027]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT2 Training for generation\n",
        "\n",
        "Model: gpt2\n",
        "\n",
        "https://huggingface.co/gpt2"
      ],
      "metadata": {
        "id": "q2GRGiKYMBWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from transformers import pipeline, set_seed\n",
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import TextGenerationPipeline"
      ],
      "metadata": {
        "id": "4IbaDbNYMGw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Dataset and the DataLoader\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Load in the data\n",
        "data = pd.read_csv(\"/content/drive/My Drive/Grad/Text Analysis/fine_tune_data_all_eras.csv\")\n",
        "data.drop(columns=['label'], inplace=True)\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, block_size=128):\n",
        "        self.data = dataframe['text'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.block_size = block_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.data[idx]\n",
        "        tokens = self.tokenizer(\n",
        "            text,\n",
        "            return_tensors='pt',\n",
        "            truncation=True,\n",
        "            max_length=self.block_size,\n",
        "            padding='max_length',\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': tokens['input_ids'].squeeze(),\n",
        "            'attention_mask': tokens['attention_mask'].squeeze()\n",
        "        }\n",
        "\n",
        "# Tokenize the dataset\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Add a new special token for padding\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "dataset = CustomDataset(data, tokenizer)\n",
        "\n",
        "# Set DataLoader\n",
        "train_dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoEwYtoqSaj_",
        "outputId": "4797b487-d89c-49fd-c865-e5f1caad293a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Move the model to the GPU if available\n",
        "model.to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LnuAbHUM4hR",
        "outputId": "56444cfd-3e6e-48c7-e567-dfdf0c95384f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the default loss and Trainer/TrainingArguments class:"
      ],
      "metadata": {
        "id": "t2kjXyj3V-ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=8,\n",
        "    per_device_train_batch_size=4,\n",
        "    save_steps=10_000,\n",
        ")\n",
        "\n",
        "# Define a data collator for language modeling\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n",
        "\n",
        "# Train the model using the Trainer class\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    data_collator=data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "nMKDe_5DVVnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, call the trainer\n",
        "%time trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "1MU6w5OyN72m",
        "outputId": "aec93060-bf7d-4404-a3d1-2bf6c579e11d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2224' max='2224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2224/2224 06:37, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.161600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.432400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>2.016600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.734900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6min 29s, sys: 1.79 s, total: 6min 31s\n",
            "Wall time: 6min 38s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2224, training_loss=2.26788083083338, metrics={'train_runtime': 398.1044, 'train_samples_per_second': 22.346, 'train_steps_per_second': 5.586, 'total_flos': 581113479168000.0, 'train_loss': 2.26788083083338, 'epoch': 8.0})"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model\n",
        "drive_path = \"/content/drive/My Drive/Grad/Text Analysis/\"\n",
        "\n",
        "model.save_pretrained(drive_path + \"tAIylors-version-model-generate-v2\")\n",
        "tokenizer.save_pretrained(drive_path + \"tAIylors-version-tokenizer-generate-v2\")"
      ],
      "metadata": {
        "id": "D-6K70INN7dD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d93e23-6cd6-4e66-f6dc-bf60733d8c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/Grad/Text Analysis/tAIylors-version-tokenizer-generate-v2/tokenizer_config.json',\n",
              " '/content/drive/My Drive/Grad/Text Analysis/tAIylors-version-tokenizer-generate-v2/special_tokens_map.json',\n",
              " '/content/drive/My Drive/Grad/Text Analysis/tAIylors-version-tokenizer-generate-v2/vocab.json',\n",
              " '/content/drive/My Drive/Grad/Text Analysis/tAIylors-version-tokenizer-generate-v2/merges.txt',\n",
              " '/content/drive/My Drive/Grad/Text Analysis/tAIylors-version-tokenizer-generate-v2/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try some generations"
      ],
      "metadata": {
        "id": "Rw65hW-6RV2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Play around with text generation\n",
        "\n",
        "# Path to the directory where you saved the fine-tuned GPT-2 model and tokenizer\n",
        "model_dir = \"/content/drive/My Drive/Grad/Text Analysis/tAIylors-version-model-generate-v2\"\n",
        "tokenizer_dir = \"/content/drive/My Drive/Grad/Text Analysis/tAIylors-version-tokenizer-generate-v2\"\n",
        "\n",
        "# Load the fine-tuned GPT2 language modeling head model\n",
        "fine_tuned_model = GPT2LMHeadModel.from_pretrained(model_dir)\n",
        "\n",
        "# Load the GPT2 tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_dir)\n",
        "\n",
        "# Move the model to the GPU if available\n",
        "fine_tuned_model.to(\"cuda\")\n",
        "\n",
        "# Create a text generation pipeline using the fine-tuned GPT2 model and tokenizer\n",
        "generator = TextGenerationPipeline(model=fine_tuned_model, tokenizer=tokenizer, device=0)"
      ],
      "metadata": {
        "id": "OU1MXHpbQrN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top k instead of adjusting temperature works better. Adjusting temperature would make it get \"stuck\" often and repeat the same thing over and over."
      ],
      "metadata": {
        "id": "YVjxztYkmbc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the seed for reproducibility\n",
        "set_seed(13)\n",
        "\n",
        "# Text prompt for generation\n",
        "text_prompt = '''Create a song about staying up until midnight for a man who will never show up'''\n",
        "\n",
        "# Generate text using the fine-tuned model with top-k sampling\n",
        "generated_text = generator(text_prompt, max_length=200, num_return_sequences=1,\n",
        "                           do_sample=True, top_k=50)\n",
        "\n",
        "print(generated_text[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fvVZHTMmUIq",
        "outputId": "d78380ea-3ffb-4dc5-c447-5a33fb7a0bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create a song about staying up until midnight for a man who will never show up And bring upon myself the dignity of my office and my mattress This was a national conversation, one that should last forever And it was a stately love affair That should be celebrated And given the gravity of my crime They might find a movie that would play The beat of your heart, oh-oh Whoa, whoa, it's you, it's me, it's me I'm the only one of me, honey (Oh) and you're the only one of me, sweet (Mmh, I miss you) That should be celebrated (But given the gravity of my crime) And given the gravity of my crime You're the only one of you (Ooh) and you're the only one of you, yeah, yeah Girl, are we out of line? Are we in the clear yet? Are we out of the woods yet? Are we in the clear yet? Are we in the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HQX4sjk8jUEq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}